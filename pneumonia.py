# -*- coding: utf-8 -*-
"""Pneumonia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wp49_sAQp3_fH7W9ZIaKTRyxixRTa6ts
"""

!pip install scikeras

# Commented out IPython magic to ensure Python compatibility.
import sys
import os
import argparse

import random

import time
import datetime

from collections import Counter

import numpy as np
import pandas as pd

import shutil
from tqdm import tqdm

import inspect
import gc

import re

from PIL import Image
import cv2

import keras

from tensorflow.keras.utils import to_categorical

from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras import models
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, GlobalAveragePooling1D, GlobalAveragePooling2D, Flatten, BatchNormalization, Dense


from tensorflow.keras.applications.inception_v3 import InceptionV3


from tensorflow.keras.constraints import MaxNorm


from tensorflow.keras import optimizers
from tensorflow.keras.optimizers import Adam, SGD , RMSprop


from tensorflow.keras import backend as K
K.set_image_data_format('channels_first')


from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau

from scikeras.wrappers import KerasClassifier

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report


from mlxtend.plotting import plot_confusion_matrix

import tensorflow as tf



from IPython.display import display

import seaborn as sns

from matplotlib.pyplot import figure
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# %matplotlib inline

# Creates directory, if directory exists removes if remove parameter is set to True
def create_directory(directory_path, remove=False):
    if remove and os.path.exists(directory_path):
        try:
            shutil.rmtree(directory_path)
            os.mkdir(directory_path)
        except:
            print("Could not remove directory : ", directory_path)
            return False
    else:
        try:
            os.mkdir(directory_path)
        except:
            print("Could not create directory: ", directory_path)
            return False

    return True

# Removes directory, if directory exists
def remove_directory(directory_path):
    if os.path.exists(directory_path):
        try:
            shutil.rmtree(directory_path)
        except:
            print("Could not remove directory : ", directory_path)
            return False

    return True

def clear_directory(directory_path):
    dirs_files = os.listdir(directory_path)

    for item in dirs_files:
#         item_path = os.path.join(directory_path, item)
        item_path = directory_path+ item

        try:
            if os.path.isfile(item_path):
                os.unlink(item_path)
            elif os.path.isdir(item_path):
                shutil.rmtree(item_path)
        except Exception as e:
            print(e)

    return True


def remove_empty_folders(path, removeRoot=True):
    if not os.path.isdir(path):
        return

    # remove empty subfolders
    files = os.listdir(path)

    if len(files):
        for f in files:
            fullpath = os.path.join(path, f)

            if os.path.isdir(fullpath):
                remove_empty_folders(fullpath)

    # if folder empty, delete it
    files = os.listdir(path)

    if len(files) == 0 and removeRoot:
        print("Removing empty folder:", path)
        os.rmdir(path)


def dir_file_count(directory):
    return sum([len(files) for r, d, files in os.walk(directory)])

# print date and time for given type of representation
def date_time(x):
    if x==1:
        return 'Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())
    if x==2:
        return 'Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())
    if x==3:
        return 'Date now: %s' % datetime.datetime.now()
    if x==4:
        return 'Date today: %s' % datetime.date.today()

# prints a integer for degugging
def debug(x):
    print("-"*40, x, "-"*40)

# Removes everything except alphabetical and selected characters from name string
def name_correct(name):
    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()

def get_reset_subplot_params(nrows, ncols, dpi):
    subplot_params = {}
    subplot_params["nrows"] = nrows
    subplot_params["ncols"] = ncols

    subplot_params["figsize_col"] = subplot_params["ncols"]*2.5
    subplot_params["figsize_row"] = subplot_params["nrows"]*2.5
    subplot_params["dpi"] = dpi
    subplot_params["facecolor"] = 'w'
    subplot_params["edgecolor"] = 'k'
    subplot_params["subplot_kw"] = {'xticks': [], 'yticks': []}
    subplot_params["axes.titlesize"] = 'small'
    subplot_params["hspace"] = 0.5
    subplot_params["wspace"] = 0.3

    return subplot_params

def get_reset_plot_params(figsize=(15, 5), title="", xlabel ="", ylabel="", legends=[], title_fontsize = 18, label_fontsize = 14, image_file_name="", save = False, dpi=100, update_image=True):
    plot_params = {}

    plot_params["figsize"] = figsize

    plot_params["title"] = title

    plot_params["xlabel"] = xlabel
    plot_params["ylabel"] = ylabel

    plot_params["legends"] = legends

    plot_params["title_fontsize"] = title_fontsize
    plot_params["axes.titlesize"] = "small"
    plot_params["label_fontsize"] = label_fontsize

    plot_params["image_file_name"] = image_file_name
    plot_params["save"] = save
    plot_params["update_image"] = update_image

    plot_params["subplot"] = None
    return plot_params

def select_image_by_category(image_dir, image_count_per_category):
    classes = os.listdir(image_dir)
    class_count = len(classes)

    image_file_paths = {}

    for i in range(class_count):
        subdir_path = image_dir+"/"+classes[i]
        subdir_files = os.listdir(subdir_path)

        subdir_file_count = len(subdir_files)

        subdir_file_mem = {}

        subdir_file_index = -1

        image_file_paths[classes[i]] = []

        for j in range(image_count_per_category):
            while subdir_file_index in subdir_file_mem:
                subdir_file_index = random.randint(0, subdir_file_count-1)

            subdir_file_mem[subdir_file_index] = 1

            subdir_file_name = subdir_files[subdir_file_index]
            subdir_file_path = subdir_path+ "/" + subdir_file_name

            image_file_paths[classes[i]].append(subdir_file_path)

    return image_file_paths


def get_fig_axs(subplot_params):
    fig, axs = plt.subplots(
        nrows=subplot_params["nrows"], ncols=subplot_params["ncols"],
        figsize=(subplot_params["figsize_col"], subplot_params["figsize_row"]),
        dpi=subplot_params["dpi"], facecolor=subplot_params["facecolor"],
        edgecolor=subplot_params["edgecolor"], subplot_kw=subplot_params["subplot_kw"])

    return fig, axs


def plot_sample_image(image_file_paths, plot_params, subplot_params, update_image=True):
    fig, axs = get_fig_axs(subplot_params)

    plt.rcParams.update({'axes.titlesize': plot_params["axes.titlesize"]})
    plt.subplots_adjust(hspace=subplot_params["hspace"], wspace=subplot_params["wspace"])


    i=0
    for img_filepath in image_file_paths:
        img = cv2.imread(img_filepath, 1)
        plt.title(img_filepath.split("/")[-1])
        plt.subplot(subplot_params["nrows"], subplot_params["ncols"], i+1)
        plt.imshow(img)

        plt.xticks([])
        plt.yticks([])

        i=i+1

    if plot_params["update_image"] and os.path.exists(plot_params["image_file_name"]):
        os.remove(plot_params["image_file_name"])
    if plot_params["save"]:
        fig.savefig(plot_params["image_file_name"], dpi=plot_params["dpi"])

    plt.tight_layout()
    plt.show()


def show_class_sample_images(directory, image_count_per_category=5, save=False, dpi=100, update_image=False):
    class_count = len(os.listdir(directory))
    print("Number of Class: ", class_count)
    sample_img_by_class = select_image_by_category(directory, image_count_per_category)
    for class_name in sample_img_by_class:
        plot_params = get_reset_plot_params(image_file_name="img.png", save = save, dpi=dpi, update_image=update_image)
        subplot_params = get_reset_subplot_params(nrows=1, ncols=image_count_per_category, dpi=dpi)
        print("%s%s%s"%("-"*55, name_correct(class_name), "-"*55))
        plot_sample_image(sample_img_by_class[class_name], plot_params, subplot_params)
        print("")
    print("%s%s%d%s"%("-"*55, "All Class Printed:", class_count, "-"*55))

# count number of files in each subdirectory of a directory
def subdirectory_file_count(master_directory):
    subdirectories = os.listdir(master_directory)
    subdirectory_count = len(subdirectories)

    subdirectory_names = []
    subdirectory_file_counts = []

    for subdirectory in subdirectories:
        current_directory = os.path.join(master_directory, subdirectory)
        file_count = len(os.listdir(current_directory))
        subdirectory_names.append(subdirectory)
        subdirectory_file_counts.append(file_count)

    return subdirectory_names, subdirectory_file_counts



# show barplot
def bar_plot(x, y, plot_property):
    if plot_property['subplot']:
        plt.subplot(plot_property['subplot'])
    sns.barplot(x=x, y=y)
    plt.title(plot_property['title'], fontsize=plot_property['title_fontsize'])
    plt.xlabel(plot_property['xlabel'], fontsize=plot_property['label_fontsize'])
    plt.ylabel(plot_property['ylabel'], fontsize=plot_property['label_fontsize'])
    plt.xticks(range(len(x)), x)

# show bar plot for count of labels in subdirectory of a directory
def count_bar_plot(master_directory, plot_property):
    dir_name, dir_file_count = subdirectory_file_count(master_directory)
    x = [name_correct(i) for i in dir_name]
    # x = dir_name
    y = dir_file_count
    bar_plot(x, y, plot_property)


# show bar plot for count of labels in subdirectory of a training, validation, testing directory
def show_train_val_test(training_dir, validation_dir, testing_dir, plot_property):
    plt.figure(figsize=plot_property['figsize'])

    title = plot_property['title']
    plot_property['title'] = title + " (Training)"
    subplot_no = plot_property['subplot']

    count_bar_plot(training_dir, plot_property)


    plot_property['title'] = title + " (Validation)"
    plot_property['subplot'] = subplot_no+1
    count_bar_plot(validation_dir, plot_property)


    plot_property['title'] = title + " (Testing)"
    plot_property['subplot'] = subplot_no + 2
    count_bar_plot(testing_dir, plot_property)

    plt.show()

# reset tensorflow graph tp free up memory and resource allocation
def reset_graph(model=None):
    if model:
        try:
            del model
        except:
            return False


    K.clear_session()

    gc.collect()

    return True


# reset callbacks
def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):
    checkpoint = None
    reduce_lr = None
    early_stopping = None
    tensorboard = None

reset_graph()
reset_callbacks()

# Configure input/ output directory
# Configure training, validation, testing directory

input_directory = r"data/input/chest_xray/"
output_directory = r"data/output/chest_xray/"

training_dir = input_directory +r"train"
validation_dir = input_directory + r"val"
testing_dir = input_directory + r"test"


figure_directory = r"data/output/figures"

figure_directory = "data/output/figures"
if not os.path.exists(figure_directory):
    os.makedirs("data/output/figures",exist_ok=True)


file_name_pred_batch = figure_directory+r"/result"
file_name_pred_sample = figure_directory+r"/sample"

from google.colab import drive
drive.mount('/content/drive')
zip_path="/content/drive/MyDrive/Colab Notebooks/archive.zip"

import os
import zipfile
os.makedirs('/content/data/input',exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall('/content/data/input/chest_xray')

import os

# First, let's confirm what zip_path is
# If you didn't define zip_path, it's likely a variable from a previous cell.
# Please ensure the zip extraction completed successfully without errors.

# Assuming the extraction target is '/content/data/input/chest_xray'
extracted_base_dir = '/content/data/input/chest_xray'

print(f"Contents of {extracted_base_dir}:")
if os.path.exists(extracted_base_dir):
    for item in os.listdir(extracted_base_dir):
        print(f"  - {item} (Is Dir: {os.path.isdir(os.path.join(extracted_base_dir, item))})")
else:
    print(f"Error: {extracted_base_dir} does not exist. Zip extraction might have failed or extracted elsewhere.")

print("\n--- Looking for 'train' or similar subdirectories ---")
possible_training_dirs = []
for root, dirs, files in os.walk(extracted_base_dir):
    if 'train' in dirs:
        possible_training_dirs.append(os.path.join(root, 'train'))
    if 'NORMAL' in dirs and 'PNEUMONIA' in dirs:
        # This covers cases where NORMAL/PNEUMONIA are directly under the extracted_base_dir
        # or under another unexpected subfolder.
        if 'train' not in dirs: # Only if train dir is not present in same level
             print(f"Found NORMAL/PNEUMONIA directly under: {root}")
             possible_training_dirs.append(root)


if possible_training_dirs:
    print("\nPossible directories containing 'NORMAL' and 'PNEUMONIA' subfolders (or 'train' with them inside):")
    for p_dir in possible_training_dirs:
        print(f"  - {p_dir}")
        if os.path.exists(os.path.join(p_dir, 'NORMAL')) and os.path.exists(os.path.join(p_dir, 'PNEUMONIA')):
            print(f"    (Contains 'NORMAL' and 'PNEUMONIA' directories!)")
            # This is likely your correct training_dir
            # Set training_dir = p_dir and re-run your show_class_sample_images call
else:
    print("No 'train' directory or direct 'NORMAL'/'PNEUMONIA' subfolders found within the extracted path.")

# Once you've identified the correct path, set your training_dir accordingly:
# training_dir = "THE_CORRECT_PATH_YOU_FOUND"
# Then rerun:
# show_class_sample_images(training_dir, image_count_per_category=5)

# 1. Set your training_dir to the correct path you found:
training_dir = '/content/data/input/chest_xray/chest_xray/train'

# 2. Call the function with only the arguments that do not cause an error.
# Remove 'update_image', 'dpi', and 'save' from the function call.
show_class_sample_images(training_dir, image_count_per_category=5,save=False,dpi=100,update_image=False)

show_class_sample_images(training_dir, image_count_per_category=5)

import os

# --- Step 1: Identify the correct base directory ---
# Based on previous output, it seems your 'train', 'val', 'test' folders are inside:
base_data_dir = '/content/data/input/chest_xray/chest_xray' # <--- CONFIRM THIS PATH IS CORRECT

print(f"--- Checking Base Data Directory: {base_data_dir} ---")
if not os.path.exists(base_data_dir):
    print(f"Error: Base data directory '{base_data_dir}' does NOT exist.")
    print("Please check if your zip extraction created this path correctly.")
    exit() # Stop if the base path is wrong

print(f"Contents of {base_data_dir}: {os.listdir(base_data_dir)}")


# --- Step 2: Define the specific training, validation, and testing directories ---
training_dir = os.path.join(base_data_dir, 'train')
validation_dir = os.path.join(base_data_dir, 'val')
testing_dir = os.path.join(base_data_dir, 'test')

# --- Step 3: Verify each directory exists and list its immediate contents (e.g., NORMAL, PNEUMONIA) ---

print("\n--- Verifying Individual Data Directories ---")

# Training Directory
print(f"\nChecking Training Directory: {training_dir}")
if os.path.exists(training_dir):
    print(f"  '{training_dir}' exists.")
    train_contents = os.listdir(training_dir)
    print(f"  Contents: {train_contents}")
    if 'NORMAL' in train_contents and 'PNEUMONIA' in train_contents:
        print(f"  --> 'NORMAL' and 'PNEUMONIA' subfolders found!")
    else:
        print(f"  Warning: 'NORMAL' or 'PNEUMONIA' not found directly in '{training_dir}'.")
else:
    print(f"  Error: Training directory '{training_dir}' does NOT exist.")


# Validation Directory
print(f"\nChecking Validation Directory: {validation_dir}")
if os.path.exists(validation_dir):
    print(f"  '{validation_dir}' exists.")
    val_contents = os.listdir(validation_dir)
    print(f"  Contents: {val_contents}")
    if 'NORMAL' in val_contents and 'PNEUMONIA' in val_contents:
        print(f"  --> 'NORMAL' and 'PNEUMONIA' subfolders found!")
    else:
        print(f"  Warning: 'NORMAL' or 'PNEUMONIA' not found directly in '{validation_dir}'.")
else:
    print(f"  Error: Validation directory '{validation_dir}' does NOT exist.")


# Testing Directory
print(f"\nChecking Testing Directory: {testing_dir}")
if os.path.exists(testing_dir):
    print(f"  '{testing_dir}' exists.")
    test_contents = os.listdir(testing_dir)
    print(f"  Contents: {test_contents}")
    if 'NORMAL' in test_contents and 'PNEUMONIA' in test_contents:
        print(f"  --> 'NORMAL' and 'PNEUMONIA' subfolders found!")
    else:
        print(f"  Warning: 'NORMAL' or 'PNEUMONIA' not found directly in '{testing_dir}'.")
else:
    print(f"  Error: Testing directory '{testing_dir}' does NOT exist.")

print("\n--- After running this, if all directories are confirmed to exist, ---")
print("--- then you can confidently run your 'show_train_val_test' function. ---")

# REMEMBER: Before running show_train_val_test, you must have run the cell that defines it,
# along with the 'plot_params = get_reset_plot_params()' and other plot_params settings.

# Example of what might be in this cell(s) - Adjust based on your actual notebook
import os
import zipfile
# import matplotlib.pyplot as plt # You'll need this later for plotting

# Define zip_path if it's not already defined globally in your notebook
# Example: zip_path = '/path/to/your/chest_xray_dataset.zip'

# Create the base directory if it doesn't exist
os.makedirs('/content/data/input', exist_ok=True)

# Extract the zip file (ensure zip_path is correctly set)
# with zipfile.ZipFile(zip_path, 'r') as zip_ref:
#     zip_ref.extractall('/content/data/input/chest_xray')

# --- If you already ran this and the files are extracted, you might not need to run it again
# --- in a single session, but always run it after a fresh restart or if you delete the data.

import os # Ensure os is imported

base_data_dir = '/content/data/input/chest_xray/chest_xray'
training_dir = os.path.join(base_data_dir, 'train')
validation_dir = os.path.join(base_data_dir, 'val')
testing_dir = os.path.join(base_data_dir,'test')

# Function to get/reset plot parameters
def get_reset_plot_params():
    params = {
        'figsize': (10, 5),
        'title_fontsize': 12,
        'label_fontsize': 10,
        'title': '',
        'subplot': None # Ensure this is NOT 131 or any fixed value
    }
    return params

# Function to correct/format class names
def name_correct(class_name):
    if class_name == 'NORMAL':
        return 'Normal'
    elif class_name == 'PNEUMONIA':
        return 'Pneumonia'
    else:
        return class_name # Return as is if not normal/pneumonia

# Main plotting function (this is a simplified example, your actual one is more complex)
def show_train_val_test(train_dir, val_dir, test_dir, plot_params):
    import matplotlib.pyplot as plt # Ensure Matplotlib is imported here or globally

    # Get counts of images in each class for each directory
    train_normal_count = len(os.listdir(os.path.join(train_dir, 'NORMAL')))
    train_pneumonia_count = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))

    val_normal_count = len(os.listdir(os.path.join(val_dir, 'NORMAL')))
    val_pneumonia_count = len(os.listdir(os.path.join(val_dir, 'PNEUMONIA')))

    test_normal_count = len(os.listdir(os.path.join(test_dir, 'NORMAL')))
    test_pneumonia_count = len(os.listdir(os.path.join(test_dir, 'PNEUMONIA')))

    # Labels for the bars
    labels = ['Normal', 'Pneumonia']

    # Create the figure and subplots (this is usually handled dynamically within the function)
    fig, axes = plt.subplots(1, 3, figsize=plot_params.get('figsize', (18, 4))) # Use figsize from plot_params

    # Plot Training data
    axes[0].bar(labels, [train_normal_count, train_pneumonia_count], color=['skyblue', 'salmon'])
    axes[0].set_title(plot_params.get('title', 'Number of Cases') + ' (Training)', fontsize=plot_params.get('title_fontsize', 13))
    axes[0].set_ylabel('Count', fontsize=plot_params.get('label_fontsize', 10))
    axes[0].tick_params(axis='x', labelsize=plot_params.get('label_fontsize', 10))
    axes[0].tick_params(axis='y', labelsize=plot_params.get('label_fontsize', 10))

    # Plot Validation data
    axes[1].bar(labels, [val_normal_count, val_pneumonia_count], color=['skyblue', 'salmon'])
    axes[1].set_title(plot_params.get('title', 'Number of Cases') + ' (Validation)', fontsize=plot_params.get('title_fontsize', 13))
    axes[1].set_ylabel('Count', fontsize=plot_params.get('label_fontsize', 10))
    axes[1].tick_params(axis='x', labelsize=plot_params.get('label_fontsize', 10))
    axes[1].tick_params(axis='y', labelsize=plot_params.get('label_fontsize', 10))

    # Plot Testing data
    axes[2].bar(labels, [test_normal_count, test_pneumonia_count], color=['skyblue', 'salmon'])
    axes[2].set_title(plot_params.get('title', 'Number of Cases') + ' (Testing)', fontsize=plot_params.get('title_fontsize', 13))
    axes[2].set_ylabel('Count', fontsize=plot_params.get('label_fontsize', 10))
    axes[2].tick_params(axis='x', labelsize=plot_params.get('label_fontsize', 10))
    axes[2].tick_params(axis='y', labelsize=plot_params.get('label_fontsize', 10))

    plt.tight_layout()
    plt.show()

plot_params = get_reset_plot_params()
plot_params['figsize'] = (18,4)
plot_params['title_fontsize'] = 13
plot_params['label_fontsize'] = 10
plot_params['title'] = "Number of Cases"
# DO NOT add this line: plot_params['subplot'] = 131

show_train_val_test(training_dir, validation_dir, testing_dir, plot_params)
classes = os.listdir(training_dir)
classes = [name_correct(i) for i in classes]

# batch_size = 32

# target_size = (299, 299)
# color_mode = "rgb"


rescale = 1./255
target_size = (150, 150)
batch_size = 163
class_mode = "categorical"
# class_mode = "binary"


train_datagen = ImageDataGenerator(
    rescale=rescale,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)


train_generator = train_datagen.flow_from_directory(
    training_dir,
    target_size=target_size,
    class_mode=class_mode,
    batch_size=batch_size,
    shuffle=True)


validation_datagen = ImageDataGenerator(rescale=rescale)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=target_size,
    class_mode=class_mode,
    batch_size=dir_file_count(validation_dir),
    shuffle = False)


test_datagen = ImageDataGenerator(rescale=rescale)

test_generator = test_datagen.flow_from_directory(
    testing_dir,
    target_size=target_size,
    class_mode=class_mode,
    batch_size=dir_file_count(testing_dir),
    shuffle = False)

from sklearn.utils import class_weight
def get_weight(y):
    class_weight_current =  class_weight.compute_class_weight('balanced', np.unique(y), y)
    return class_weight_current

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1), padding='same'),  # Added padding
    MaxPooling2D((2, 2)),

    Conv2D(64, (3, 3), activation='relu', padding='same'),  # Added padding
    MaxPooling2D((2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')  # Fixed typo: 'signolo' → 'sigmoid'
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',  # For binary classification
    metrics=['accuracy']
)

from sklearn.utils import class_weight
import numpy as np

# Calculate class weights
class_weights = class_weight.compute_class_weight(
    'balanced',
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)
class_weight = dict(enumerate(class_weights))  # Convert to {0: weight0, 1: weight1}

print(class_weight)  # Example output: {0: 0.8, 1: 1.2}

import numpy as np
from sklearn.utils import class_weight

# 1. Calculate class weights (returns numpy array)
class_weight_array = class_weight.compute_class_weight(
    'balanced',
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)

# 2. Print the array (matches your output format)
print("Class weights (array):", class_weight_array)

# 3. Convert to dictionary for Keras (if needed)
class_weight_dict = dict(enumerate(class_weight_array))
print("Class weights (dict):", class_weight_dict)

import os
import time

# 1. Set up base directory
output_directory = "data/output/chest_xray/"
os.makedirs(output_directory, exist_ok=True)

# 2. Create main directories
main_model_dir = os.path.join(output_directory, "models")
main_log_dir = os.path.join(output_directory, "logs")

def create_directory(path, remove=False):
    if remove and os.path.exists(path):
        import shutil
        shutil.rmtree(path)
    os.makedirs(path, exist_ok=True)

create_directory(main_model_dir, remove=True)
create_directory(main_log_dir, remove=True)

# 3. Create timestamped subdirectories
timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
model_dir = os.path.join(main_model_dir, timestamp)
log_dir = os.path.join(main_log_dir, timestamp)

create_directory(model_dir)
create_directory(log_dir)

# 4. Define model filename template
model_file = os.path.join(model_dir, "epoch-{epoch:02d}_valacc-{val_acc:.2f}_valloss-{val_loss:.2f}.hdf5")
print(f"Model will be saved to: {model_file}")

reset_graph()
reset_callbacks()

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard

# Set file name and paths (you can adjust if needed)
model_file = 'best_model.h5'
log_dir = 'logs'  # You can change this
batch_size = 32   # Make sure this matches your training setup

# Callbacks
checkpoint = ModelCheckpoint(
    model_file,
    monitor='val_accuracy',     # ✅ modern name (not val_acc)
    save_best_only=True,
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    verbose=1,
    restore_best_weights=True
)

tensorboard = TensorBoard(
    log_dir=log_dir,
    update_freq='batch'
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    patience=5,
    cooldown=2,
    min_lr=1e-10,
    verbose=1
)

# Final list of callbacks
callbacks = [checkpoint, reduce_lr, early_stopping, tensorboard]

print("✅ Callbacks are set.")

def get_conv_model():
    model = Sequential()
    model.add(Conv2D(16, (3, 3), activation='relu', padding="same", input_shape=(3,150,150)))
    model.add(Conv2D(16, (3, 3), padding="same", activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(32, (3, 3), activation='relu', padding="same", input_shape=(3,150,150)))
    model.add(Conv2D(32, (3, 3), padding="same", activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu', padding="same"))
    model.add(Conv2D(64, (3, 3), padding="same", activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding="same"))
    model.add(Conv2D(96, (3, 3), padding="valid", activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding="same"))
    model.add(Conv2D(128, (3, 3), padding="valid", activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Flatten())

    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.4))
    model.add(Dense(2 , activation='softmax'))


    print(model.summary())

    return model

# Load and configure model InceptionV3 for fine-tuning with new class labels
def get_model():

#     base_model = InceptionV3(weights=None, include_top=False)
    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

    x = base_model.output

#     x = Dropout(0.5)(x)

#     x = GlobalAveragePooling2D()(x)

#     x = Dense(512, activation='relu')(x)
#     # x = Dense(1024, activation='relu')(x)

    x = BatchNormalization()(x)

# #     predictions = Dense(2, activation='sigmoid')(x)
    predictions = Dense(2, activation='softmax')(x)


    model = Model(inputs=base_model.input, outputs=predictions)


    for layer in base_model.layers:
        layer.trainable = False


#     for layer in model.layers[:249]:
#         layer.trainable = False
#     for layer in model.layers[249:]:
#         layer.trainable = True


    model.summary()

    return model

print("Getting Base Model", date_time(1))
# model = get_model()
model = get_conv_model()
# model = keras.models.load_model("data/output/models/2018-12-15 00-26-45/13-val_acc-0.70-val_loss-0.58.hdf5")

from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# Assuming you are using a categorical generator
class_labels = train_generator.classes
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(class_labels),
    y=class_labels
)

# Convert to dictionary format
class_weight = dict(enumerate(class_weights))

import datetime
from tensorflow.keras import optimizers

# 1. Verify generators
print("Generator verification:")
try:
    sample_batch = next(iter(train_generator))
    print(f"Train batch shape: {sample_batch[0].shape}")  # Should match input_shape
except Exception as e:
    print(f"Generator error: {str(e)}")

# 2. Model compilation
model.compile(
    optimizer=optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# 3. Training with error handling
try:
    print(f"\nStarting Model Training at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    history = model.fit(
        train_generator,
        steps_per_epoch=len(train_generator),  # Fixed: = instead of -
        epochs=10,
        validation_data=validation_generator,
        validation_steps=len(validation_generator),
        callbacks=callbacks,
        class_weight=class_weight if class_weight else None,  # Handle None case
        verbose=1
    )

    print(f"\nCompleted Model Training at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nTraining accuracy: {history.history['accuracy'][-1]:.4f}")
    print(f"Validation accuracy: {history.history['val_accuracy'][-1]:.4f}")

except Exception as e:
    print(f"\nTraining failed: {str(e)}")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import numpy as np

# Sample model setup (replace with your actual model)
model = Sequential([
    Dense(64, activation='relu', input_shape=(10,)),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Generate dummy data (replace with your real data)
X_train = np.random.rand(1000, 10)
y_train = np.random.randint(0, 2, size=(1000,))

# Train the model and capture history
history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.2  # Creates validation data automatically
)

import matplotlib.pyplot as plt

# Check if 'history' exists and has data
if history and 'accuracy' in history.history:

    xlabel = 'Epoch'
    legends = ['Training', 'Validation']
    ylim_pad = [0.01, 0.1]

    plt.figure(figsize=(15, 5))

    # Accuracy Plot
    y1 = history.history['accuracy']
    y2 = history.history['val_accuracy']

    min_y = min(min(y1), min(y2)) - ylim_pad[0]
    max_y = max(max(y1), max(y2)) + ylim_pad[0]

    plt.subplot(1, 2, 1)
    plt.plot(y1)
    plt.plot(y2)
    plt.title('Model Accuracy', fontsize=17)
    plt.xlabel(xlabel, fontsize=15)
    plt.ylabel('Accuracy', fontsize=15)
    plt.ylim(min_y, max_y)
    plt.legend(legends, loc='lower right')
    plt.grid()

    # Loss Plot
    y1 = history.history['loss']
    y2 = history.history['val_loss']

    min_y = min(min(y1), min(y2)) - ylim_pad[1]
    max_y = max(max(y1), max(y2)) + ylim_pad[1]

    plt.subplot(1, 2, 2)
    plt.plot(y1)
    plt.plot(y2)
    plt.title('Model Loss', fontsize=17)
    plt.xlabel(xlabel, fontsize=15)
    plt.ylabel('Loss', fontsize=15)
    plt.ylim(min_y, max_y)
    plt.legend(legends, loc='upper right')
    plt.grid()

    plt.tight_layout()
    plt.show()

else:
    print("⚠ 'history' object not found or no accuracy data available.")

dir_name = r"data/output/chest_xray/"
dirs = os.listdir(dir_name)
for i in range(len(dirs)):
    print(i, dirs[i])

cur_dir =dir_name+dirs[0]+"/"
model_names = os.listdir(cur_dir)
for i in range(len(model_names)):
    print(i, model_names[i])

# Safe version with index checking
if len(model_names) > 0:  # Check if list is not empty
    model_file = cur_dir + model_names[-1]  # Uses last element instead of fixed index
    print(model_file)
else:
    print("Error: model_names list is empty")

# First, print the contents of model_names and its length
print(f"Contents of model_names: {model_names}")
print(f"Length of model_names: {len(model_names)}")

# Now, based on the output of the above line, choose a valid index.
# For example, if Length is 3, valid indices are 0, 1, 2.
# If you want the first model, use [0]. If you want the last, use [len(model_names) - 1].
# For now, let's assume you want the first one, or adjust after you see the output.
# Replace '5' with a valid index (e.g., 0, 1, 2, etc., based on the length)
model_file = cur_dir + model_names[0] + '/' + model_names[0] + '.h5' # <--- IMPORTANT: Changed index from 5 to 0 (or choose another valid one)

# Now you can print model_file as it should be defined
print(f"Selected model_file:{model_file}")

import os
print(os.listdir(cur_dir))

import os
print(os.listdir(model_file.rsplit('/', 1)[0]))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    '/content/data/input/chest_xray/chest_xray/train',
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    color_mode='rgb',             # Ensure this for 3-channel images
    shuffle=True
)

val_datagen = ImageDataGenerator(rescale=1./255)
val_generator = val_datagen.flow_from_directory(
    '/content/data/input/chest_xray/chest_xray/val',
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    color_mode='rgb',             # Same here
    shuffle=False
)

from tensorflow.keras import backend as K
K.set_image_data_format('channels_last')  # Step 1: Force correct format

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    '/content/data/input/chest_xray/chest_xray/train',
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    color_mode='rgb',
    shuffle=True
)

val_datagen = ImageDataGenerator(rescale=1./255)
val_generator = val_datagen.flow_from_directory(
    '/content/data/input/chest_xray/chest_xray/val',
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    color_mode='rgb',
    shuffle=False
)

# Debug check:
x_batch, y_batch = next(train_generator)
print(x_batch.shape)  # Should be (32, 150, 150, 3)

from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint
import os

# ------------------------ 1. Create Folders ------------------------
model_save_path = "/content/my_model.h5"

# ------------------------ 2. Prepare Data ------------------------
train_dir = '/content/data/input/chest_xray/chest_xray/train'
val_dir = '/content/data/input/chest_xray/chest_xray/val'

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(150, 150, 3)),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(64, (3, 3), activation='relu', padding='same'),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(128, (3, 3), activation='relu', padding='same'),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')  # for binary classification
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# ------------------------ 4. Add Callback to Save Model ------------------------
checkpoint = ModelCheckpoint(
    model_save_path,
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

# ------------------------ 5. Train Model ------------------------
model.fit(train_generator,validation_data=val_generator,epochs=10,callbacks=[checkpoint])

# ------------------------ 6. Load Model ------------------------
print("\nLoading the saved model...")
loaded_model = load_model(model_save_path)
print("Model loaded successfully!")

from tensorflow.keras.preprocessing.image import ImageDataGenerator
test_datagen=ImageDataGenerator(rescale=1./255)
test_generator=test_datagen.flow_from_directory(
    '/content/data/input/chest_xray/chest_xray/test',
    target_size=(150,150),
    batch_size=32,
    class_mode='binary',
    shuffle=False
)

print("results")
result  = model.evaluate(test_generator,steps=len(test_generator), verbose=1)

print("%s%.2f  "% ("Loss     : ", result[0]))
print("%s%.2f%s"% ("Accuracy : ", result[1]*100, "%"))

print("results")
y_pred = model.predict(test_generator, steps=len(test_generator), verbose=1)
y_pred = y_pred.argmax(axis=-1)
y_true=test_generator.classes

from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_size = (150, 150)

train_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    '/content/data/input/chest_xray/chest_xray/train',
    target_size=img_size,
    batch_size=32,
    class_mode='binary'  # or 'categorical' if 2+ classes
)

model.fit(
    train_generator,
    epochs=10,
    class_weight={0: class_weights[0], 1: class_weights[1]})

from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_size = (150, 150)

train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    '/content/data/input/chest_xray/chest_xray/train',
    target_size=img_size,
    batch_size=32,
    class_mode='binary'  # or 'categorical' if >2 classes
)

# Compute class weights from train_generator.labels
import numpy as np
from sklearn.utils import class_weight

y_train = train_generator.classes
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weights_dict = dict(enumerate(class_weights))

# Train the model
model.fit(train_generator, epochs=10, class_weight=class_weights_dict)

from sklearn.utils import class_weight
import numpy as np

# Compute class weights
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)

# Convert to dictionary (DO NOT use enumerate!)
class_weights_dict = {int(cls): weight for cls, weight in zip(np.unique(y_train),class_weights)}

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils import class_weight
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# ========== 1. Prepare Data ==========

img_size = (150, 150)
batch_size = 32

train_path = '/content/data/input/chest_xray/chest_xray/train'
val_path = '/content/data/input/chest_xray/chest_xray/val'
test_path = '/content/data/input/chest_xray/chest_xray/test'

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen   = ImageDataGenerator(rescale=1./255)
test_datagen  = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    val_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=img_size,
    batch_size=1,
    class_mode='binary',
    shuffle=False
)

# ========== 2. Compute Class Weights ==========

y_train = train_generator.classes
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weights_dict = {int(cls): weight for cls, weight in zip(np.unique(y_train), class_weights)}

# ========== 3. Build the Model ==========

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Binary classification
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

# ========== 4. Train the Model ==========

model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10,
    class_weight=class_weights_dict
)

# ========== 5. Evaluate ==========

# Predict on test set
y_true = test_generator.classes
y_pred_prob = model.predict(test_generator)
y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
print("\nConfusion Matrix:\n", cm)

# Classification Report
target_names = list(test_generator.class_indices.keys())
print("\nClassification Report:\n", classification_report(y_true, y_pred, target_names=target_names))

# ========== 6. Plot Confusion Matrix ==========

import seaborn as sns

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

import random
import numpy as np

numofbatch = len(test_generator)
batch_no = random.randint(0, numofbatch-1)

y_img_batch, y_true_batch = test_generator[batch_no]

# If one-hot encoded, convert to label
if y_true_batch.ndim > 1 and y_true_batch.shape[1] > 1:
    y_true_batch = y_true_batch.argmax(axis=-1)

# Model predictions
y_pred_batch = model.predict(y_img_batch)

# If sigmoid output (for binary), convert using threshold
if y_pred_batch.shape[1] == 1 or y_pred_batch.ndim == 1:
    y_pred_batch = (y_pred_batch > 0.5).astype(int).reshape(-1)
else:
    y_pred_batch = y_pred_batch.argmax(axis=-1)

# Handle scalar error
if np.isscalar(y_true_batch):
    y_true_batch = np.array([y_true_batch])
    y_pred_batch = np.array([y_pred_batch])

# Print info
sizeofbatch = len(y_true_batch)

print("-"*35)
print("%s%d" % ("Selected Batch No       : ", batch_no))
print("-"*35)
print("%s%d" % ("Batch Size              : ", sizeofbatch))
print("-"*35)
print("%s%.2f%s" % ("Batch Accuracy          : ", np.mean(y_true_batch == y_pred_batch)*100, "%"))
print("-"*35)

def show_predictions(y_img_batch, y_true, y_pred, subplot_params, plot_params, class_map, testing_dir, image_file_name, count=8, sample=True):
    fig, axs = get_fig_axs(subplot_params)
    plt.rcParams.update({'axes.titlesize': plot_params["axes.titlesize"]})
    plt.subplots_adjust(hspace=subplot_params["hspace"], wspace=subplot_params["wspace"])

    file_names = test_generator.filenames
    m = {}
    length = len(y_true)
    for i in range(0, count):
        num = i
        if sample:
            num = random.randint(0, length-1)
            while num in m:
                num = int(random.randint(0, length-1))

            m[num]=1
        plt.subplot(subplot_params["nrows"], subplot_params["ncols"], i+1)
        img = cv2.imread(testing_dir+"\\"+ file_names[num], 1)
        plt.imshow(img)

        plt.xticks([])
        plt.yticks([])
        original = class_map[y_true[num]]
        predicted = class_map[y_pred[num]]


        title_text = ("%s%s%s%s%s"%("True: ", original, "\n", "Pred: ", predicted))

        if original==predicted:
            plt.title(title_text)
        else:
            plt.title(title_text, color='red')


        if plot_params["update_image"] and os.path.exists(image_file_name):
            os.remove(image_file_name)

        fig.savefig(image_file_name, dpi=subplot_params["dpi"])

    plt.tight_layout()
    plt.show()

image_file_name_batch = figure_directory+"/result"
image_file_name_sample = figure_directory+"/sample"

batch_size_t = len(y_true_batch)

class_map = {v: k for k, v in test_generator.class_indices.items()}


dpi=100


ncols = 8
# ncols = batch_size_t if batch_size_t<ncols else ncols
# nrows = batch_size_t/ncols
# nrows = int(batch_size_t/ncols)+1 if batch_size_t%ncols else  int(batch_size_t/ncols)
nrows = 4

count = ncols*nrows


subplot_params = get_reset_subplot_params(nrows, ncols, dpi)
plot_params = get_reset_plot_params()

import matplotlib.pyplot as plt
import numpy as np
import random

def show_predictions(y_img_batch, y_true, y_pred,
                     subplot_params=None,
                     plot_params=None,
                     class_map=None,
                     testing_dir=None,
                     image_file_name=None,
                     count=8,
                     sample=True):

    # Set default values if None
    if subplot_params is None:
        subplot_params = {"hspace": 0.5}
    if plot_params is None:
        plot_params = {"axes.titlesize": 12}
    if class_map is None:
        class_map = {0: "NORMAL", 1: "PNEUMONIA"}

    # Set plotting styles
    plt.rcParams.update({'axes.titlesize': plot_params.get("axes.titlesize", 12)})
    plt.subplots_adjust(hspace=subplot_params.get("hspace", 0.5))

    # Sample indices to display
    num_images = len(y_img_batch)
    indices = random.sample(range(num_images), min(count, num_images)) if sample else list(range(min(count, num_images)))

    fig, axs = plt.subplots(1, len(indices), figsize=(15, 5))

    if len(indices) == 1:
        axs = [axs]

    for i, idx in enumerate(indices):
        ax = axs[i]
        image = y_img_batch[idx]
        true_label = int(y_true[idx])
        pred_label = int(y_pred[idx])

        ax.imshow(image)
        ax.axis('off')
        ax.set_title(f"True: {class_map[true_label]}\nPred: {class_map[pred_label]}", color="green" if true_label == pred_label else "red")

    plt.tight_layout()
    plt.show()

import numpy as np
import matplotlib.pyplot as plt
import random
import os

def show_predictions(y_img_batch, y_true, y_pred, subplot_params, plot_params, class_map, testing_dir, image_file_name, count=8, sample=True):
    # Convert inputs to arrays to avoid scalar indexing errors
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    y_img_batch = np.array(y_img_batch)

    # Ensure count does not exceed available images
    available_images = len(y_true)
    count = min(count, available_images)

    # Select random or first 'count' samples
    if sample:
        indices = random.sample(range(available_images), count)
    else:
        indices = list(range(count))

    # Use figsize_col and figsize_row from subplot_params
    fig, axs = plt.subplots(subplot_params["nrows"], subplot_params["ncols"], figsize=(subplot_params["figsize_col"], subplot_params["figsize_row"]))
    axs = axs.flatten()

    for i, idx in enumerate(indices):
        ax = axs[i]
        image = y_img_batch[idx]
        true_label = int(y_true[idx])
        pred_label = int(y_pred[idx])

        ax.imshow(image)
        ax.axis('off')
        ax.set_title(
            f"True: {class_map[true_label]}\nPred: {class_map[pred_label]}",
            fontsize=plot_params.get("fontsize", 10),
            color='red' if true_label != pred_label else 'green'
        )

    # Hide unused subplots
    for j in range(count, len(axs)):
        axs[j].axis('off')

    plt.subplots_adjust(
        hspace=subplot_params.get("hspace", 0.4),
        wspace=subplot_params.get("wspace", 0.3)
    )
    plt.show()

print("Image batch shape:", y_img_batch.shape)
print("True label batch shape:", y_true_batch.shape)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(150, 150),
    batch_size=32,            # ✅ load 32 images per batch
    class_mode='categorical',
    shuffle=True
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    directory='/content/data/input/chest_xray/chest_xray/test',
    target_size=(150, 150),
    batch_size=32,              # ✅ Increase this to show more images
    class_mode='categorical',   # or 'binary' if you're using 0/1
    shuffle=True
)

import numpy as np
import matplotlib.pyplot as plt

# ✅ Load one full test batch
y_img_batch, y_true_batch = next(test_generator)

# ✅ If y_true is one-hot encoded, convert it
if y_true_batch.ndim > 1 and y_true_batch.shape[1] > 1:
    y_true_batch = y_true_batch.argmax(axis=-1)

# ✅ Predict
y_pred_batch = model.predict(y_img_batch)
y_pred_batch = y_pred_batch.argmax(axis=-1)

# ✅ Set how many images to display
count = min(16, len(y_img_batch))  # Max 16 or batch size

# ✅ Class map
class_map = {0: "NORMAL", 1: "PNEUMONIA"}

# ✅ Plotting
nrows, ncols = 4, 4  # 4x4 grid
fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 12))
axs = axs.flatten()

for idx in range(count):
    ax = axs[idx]
    image = y_img_batch[idx]
    true_label = int(y_true_batch[idx])
    pred_label = int(y_pred_batch[idx])

    ax.imshow(image.squeeze(), cmap='gray')
    ax.axis('off')
    ax.set_title(f"True: {class_map[true_label]}\nPred: {class_map[pred_label]}", fontsize=10,
                 color='green' if true_label == pred_label else 'red')

# Hide any unused subplots
for j in range(count, len(axs)):
    axs[j].axis('off')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
import random

def show_predictions(y_img_batch, y_true, y_pred, subplot_params, plot_params, class_map, testing_dir=None, image_file_name=None, count=8, sample=True):
    y_img_batch = np.array(y_img_batch)
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    count = min(count, len(y_img_batch))
    if sample:
        indices = random.sample(range(len(y_img_batch)), count)
    else:
        indices = list(range(count))

    nrows = subplot_params["nrows"]
    ncols = subplot_params["ncols"]
    figsize = subplot_params["figsize"]

    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)
    axs = axs.flatten() if isinstance(axs, np.ndarray) else [axs]

    for i, idx in enumerate(indices):
        ax = axs[i]
        image = y_img_batch[idx]
        true_label = int(y_true[idx])
        pred_label = int(y_pred[idx])

        ax.imshow(image.squeeze(), cmap='gray')
        ax.axis('off')
        ax.set_title(
            f"True: {class_map[true_label]}\nPred: {class_map[pred_label]}",
            fontsize=plot_params.get("fontsize", 10),
            color="green" if true_label == pred_label else "red"
        )

    for j in range(count, len(axs)):
        axs[j].axis('off')

    plt.subplots_adjust(
        hspace=subplot_params.get("hspace", 0.4),
        wspace=subplot_params.get("wspace", 0.3)
    )

    if image_file_name:
        plt.savefig(image_file_name, dpi=100)
    plt.show()

nrows = 2
ncols = 4
batch_size_t = len(y_img_batch)  # actual batch size
if batch_size_t < 4:
    ncols = 1
count = nrows * ncols

subplot_params = get_reset_subplot_params(nrows, ncols)
plot_params = get_reset_plot_params()
class_map = {0: "NORMAL", 1: "PNEUMONIA"}

# 🎯 Call the function
show_predictions(
    y_img_batch,
    y_true_batch,
    y_pred_batch,
    subplot_params,
    plot_params,
    class_map,
    testing_dir=None,
    image_file_name=None,
    count=count,
    sample=True
)